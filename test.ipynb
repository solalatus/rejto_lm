{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T19:10:21.948791Z",
     "start_time": "2021-02-01T19:10:21.946271Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T19:10:23.463932Z",
     "start_time": "2021-02-01T19:10:21.950409Z"
    }
   },
   "outputs": [],
   "source": [
    "import rejto\n",
    "\n",
    "rejto_corpus = rejto.Rejto_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T19:10:24.655525Z",
     "start_time": "2021-02-01T19:10:23.466915Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# This can be an important parameter, so be aware of it...\n",
    "max_seq_length = 30\n",
    "\n",
    "# max_num_of_sents -- how many sentences should we read from the corpus \n",
    "max_num_of_sents = rejto_corpus.n_sents()\n",
    "\n",
    "def generate_rejto_word_to_id_map():\n",
    "    \"\"\"Return a dictionary mapping downcased Rejto-words to their ids.\n",
    "    Numbering starts from 1 since we use 0 for masking (!!!).\n",
    "    \"\"\"\n",
    "    words = set()\n",
    "    for word in rejto_corpus.words():\n",
    "        words.add(word.lower())\n",
    "    return {word: idx + 1 for idx, word in enumerate(sorted(words))}\n",
    "\n",
    "\n",
    "class RejtoReader:\n",
    "    \"\"\"A secondary reader class for the Rejto corpus.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word_to_id_map = generate_rejto_word_to_id_map()\n",
    "        self.id_to_word_map = {idx: word for word, idx in self.word_to_id_map.items()}\n",
    "\n",
    "    def n_words(self):\n",
    "        return len(self.word_to_id_map)\n",
    "\n",
    "    def sentence_to_ids(self, sentence):\n",
    "        \"\"\"Return the word ids of a sentence.\n",
    "        \"\"\"\n",
    "        return [self.word_to_id_map[word.lower()] for word in sentence]\n",
    "        \n",
    "    def sentences(self):\n",
    "        \"\"\"Generator yielding features from the Rejto corpus.\n",
    "        \"\"\"\n",
    "        return (self.sentence_to_ids(sentence) for sentence in rejto_corpus.sents())\n",
    "\n",
    "    def sentence_matrixes(self):\n",
    "        x = np.zeros((max_num_of_sents, max_seq_length-1))\n",
    "        y = np.zeros((max_num_of_sents, max_seq_length-1))\n",
    "        sents = self.sentences()\n",
    "        for idx, sent in enumerate(sents):\n",
    "            if idx == max_num_of_sents:\n",
    "                breaka\n",
    "            np_array = np.asarray(sent)\n",
    "            length  = min(max_seq_length, len(np_array))\n",
    "            x[idx, :length - 1] = np_array[:length - 1]\n",
    "            y[idx, :length - 1] = np_array[1:length]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T19:10:24.898374Z",
     "start_time": "2021-02-01T19:10:24.656600Z"
    }
   },
   "outputs": [],
   "source": [
    "r = RejtoReader()\n",
    "n_words = r.n_words()\n",
    "\n",
    "max_input_length = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T19:10:32.015188Z",
     "start_time": "2021-02-01T19:10:24.899411Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"30length_15epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T19:10:45.967337Z",
     "start_time": "2021-02-01T19:10:32.016289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a few starting words of a sentence: Nem\n",
      "Predicted next word: is\n",
      " Nem is\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: sejtette\n",
      " Nem is sejtette\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: ,\n",
      " Nem is sejtette ,\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: hogy\n",
      " Nem is sejtette , hogy\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: a\n",
      " Nem is sejtette , hogy a\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: fejükkel\n",
      " Nem is sejtette , hogy a fejükkel\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: játszanak\n",
      " Nem is sejtette , hogy a fejükkel játszanak\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: ,\n",
      " Nem is sejtette , hogy a fejükkel játszanak ,\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: mert\n",
      " Nem is sejtette , hogy a fejükkel játszanak , mert\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: a\n",
      " Nem is sejtette , hogy a fejükkel játszanak , mert a\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: közönség\n",
      " Nem is sejtette , hogy a fejükkel játszanak , mert a közönség\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: kiismerhetetlen\n",
      " Nem is sejtette , hogy a fejükkel játszanak , mert a közönség kiismerhetetlen\n",
      "\n",
      "Enter a few starting words of a sentence: \n",
      "Predicted next word: .\n",
      " Nem is sejtette , hogy a fejükkel játszanak , mert a közönség kiismerhetetlen .\n",
      "\n",
      "Enter a few starting words of a sentence: \\\n",
      "Unknown words -- please try again!\n",
      "\n",
      "Enter a few starting words of a sentence: \\q\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "############\n",
    "\n",
    "def str_to_input(s):\n",
    "    \"\"\"Convert a string to appropriate model input.\n",
    "    \"\"\"\n",
    "    words = [x.lower() for x in s.split()[:max_input_length]]\n",
    "    ids = [r.word_to_id_map[word] for word in words]\n",
    "    ids_array = np.asarray(ids)\n",
    "    length = min(max_input_length, len(ids_array))\n",
    "    result = np.zeros((1, max_input_length))\n",
    "    result[0, :length] = ids_array[:length]\n",
    "    return result, length\n",
    "    \n",
    "\n",
    "predicted_words = \"\"\n",
    "    \n",
    "while True:\n",
    "    s = input(\"\\nEnter a few starting words of a sentence: \") \n",
    "    if s == \"\":\n",
    "        s = predicted_words\n",
    "    elif s == \"\\q\":\n",
    "        break\n",
    "    else:\n",
    "        predicted_words+=\" \"+s\n",
    "    try:\n",
    "        x, length = str_to_input(s)\n",
    "        predictions = model(x).numpy()\n",
    "        probs = predictions[0][length - 1]\n",
    "        most_probable = np.argmax(probs)\n",
    "        word = r.id_to_word_map[most_probable]\n",
    "        print(\"Predicted next word:\", word)\n",
    "        predicted_words+=\" \"+word\n",
    "        print(predicted_words)\n",
    "    except KeyError:\n",
    "        print(\"Unknown words -- please try again!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
